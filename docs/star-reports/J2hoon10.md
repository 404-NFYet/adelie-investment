# 정지훈 — 프로젝트 기여 보고서 (STAR)

> 역할: AI 개발 (FastAPI, LangGraph)
> 기간: 2026년 2월
> 기술 스택: LangGraph, LangChain, OpenAI API, Perplexity API, Claude API, FastAPI, Redis, SSE

---

## Situation (상황)

- Adelie Investment의 핵심 차별점인 AI 기반 콘텐츠 생성과 챗봇 튜터 기능이 프로젝트 초기에는 미구현 상태였다.
- LLM 연동부터 데이터 파이프라인, 챗봇 에이전트까지 AI 관련 전 영역을 설계하고 구현해야 했다.
- 다양한 LLM 프로바이더(OpenAI, Perplexity, Claude)를 활용해야 하는 요구사항이 있었고, 각 프로바이더의 특성에 맞는 통합 인터페이스와 폴백 전략이 필요했다.
- 데이터 파이프라인과 챗봇 모듈 간에 AI 설정이 중복되는 문제가 존재하여 구조적 정리가 요구되었다.

## Task (과제)

- LangGraph 기반 AI 튜터 챗봇 에이전트 설계 및 구현
- 데이터 파이프라인 AI 서비스 레이어 구축 (6페이지 내러티브 생성)
- 멀티 LLM 프로바이더 클라이언트 개발 및 프롬프트 관리 시스템 구축
- FastAPI 백엔드 캐싱, 학습진도 API, 리더보드 등 서비스 로직 구현
- 챗봇과 데이터 파이프라인 간 공통 AI 모듈 추출 및 코드 중복 제거

## Action (행동)

### 주요 구현 사항

#### AI 튜터 챗봇

- **챗봇 서비스 복원 및 안정화**: LangGraph 기반 AI 튜터 에이전트(`tutor_agent.py`)를 구현하였다.
  - 세션 관리 API (생성, 조회, 삭제)
  - 프롬프트 정리 및 체계화
  - glossary 비동기 조회
  - 에러 재시도 로직 (최대 3회, exponential backoff)
- **chatbot prompt_loader 독립 구현**: 챗봇 전용 프롬프트 로더를 구현하였다.
  - 마크다운 기반 프롬프트 템플릿 동적 로딩 (`tutor_system`, `tutor_beginner` 등)
  - frontmatter 메타데이터(provider, model, temperature, thinking) 파싱
- **차트 시각화 도구 구현**: AI 튜터가 사용할 수 있는 차트 시각화 도구(LangChain Tool)를 구현하였다.
  - Plotly 기반의 주가 차트, 비교 차트 등 동적 생성
  - SSE 스트리밍으로 프론트엔드에 실시간 전달

#### 데이터 파이프라인 AI 레이어

- **datapipeline 레거시 정리 및 ai_service 6페이지 전환**: 기존 레거시 파이프라인 코드를 정리하고, AI 서비스 레이어를 6페이지 내러티브 생성 구조로 전환하였다.
  - page_purpose: 페이지 목적 및 요약
  - historical_case: 역사적 사례 매칭
  - narrative_body: 본문 내러티브 생성
  - hallucination_check: 환각 검증
  - chart_generation: 차트 데이터 생성
  - glossary_generation: 용어집 생성
- **AI 파이프라인 + 마크다운 프롬프트 관리 시스템**: 프롬프트 템플릿을 마크다운 파일로 관리하는 시스템을 설계하였다.
  - 9개 프롬프트 템플릿 (.md 파일)
  - frontmatter에 provider, model, temperature, thinking 등의 메타데이터 포함
  - 프롬프트별 LLM 설정을 선언적으로 관리
- **LLM 기반 historical_cases 데이터 자동 생성 스크립트**: LLM을 활용하여 과거 투자 사례 데이터를 자동으로 생성하는 스크립트를 작성하였다.
  - 프롬프트 엔지니어링을 통한 사실 기반 역사적 사례 생성
  - 생성 품질 검증 파이프라인 구축
- **generate_cases MultiProviderClient 연동 + collectors 통합**: 사례 생성 스크립트에 MultiProviderClient를 연동하여 여러 LLM 프로바이더를 활용할 수 있게 하고, 데이터 수집기(collectors)를 통합하였다.

#### 백엔드 서비스 및 인프라

- **shared/ 모듈 추출**: 챗봇과 데이터 파이프라인에서 중복되던 AI 관련 설정 및 유틸리티를 `shared/` 모듈로 추출하였다.
  - 코드 중복 제거 및 유지보수성 향상
  - 공통 LLM 클라이언트 설정, 프롬프트 유틸리티 통합
- **FastAPI Redis 캐싱 + 학습진도/리포트 API**: Redis 기반 API 응답 캐싱을 도입하여 반복 요청에 대한 응답 속도를 개선하였다.
  - 학습진도 추적 API
  - 사용자별 학습 리포트 생성 API
- **리더보드 API + 데일리 파이프라인 스케줄러**: 사용자 간 학습 순위를 제공하는 리더보드 API를 구현하고, 매일 자동으로 데이터를 수집하고 브리핑을 생성하는 스케줄러를 추가하였다.
- **파이프라인 후처리 캐시 무효화 + MV 리프레시**: 파이프라인 실행 완료 후 자동화된 후처리를 구현하였다.
  - Redis 캐시 자동 무효화
  - PostgreSQL Materialized View 리프레시
  - 최신 데이터의 즉시 반영 보장

### 기술적 의사결정

- **LangGraph 기반 에이전트 아키텍처**: 챗봇을 단순 대화 모델이 아닌 LangGraph 상태 머신으로 설계하여, 도구 호출(검색, 브리핑, 비교, 시각화, 용어집)을 포함한 복잡한 대화 플로우를 관리할 수 있게 하였다.
- **마크다운 + frontmatter 프롬프트 관리**: 프롬프트를 코드에 하드코딩하지 않고 마크다운 파일로 분리하여, AI 엔지니어가 코드 변경 없이 템플릿 파일만 수정하면 되도록 하였다.
- **MultiProviderClient 설계**: OpenAI, Perplexity, Claude 등 다양한 LLM 프로바이더를 단일 인터페이스로 추상화하여, 프로바이더 전환과 폴백이 투명하게 이루어지도록 하였다.
- **SSE 스트리밍 기반 챗봇 응답**: 사용자 경험을 위해 챗봇 응답을 Server-Sent Events로 스트리밍하여 실시간으로 응답이 표시되도록 하였다.

## Result (결과)

### 정량적 성과

| 지표 | 수치 |
|------|------|
| 커밋 수 | 34개 |
| 코드 변경량 | +16,468 / -1,979 라인 |
| 활동일 수 | 9일 |
| 챗봇 도구 수 | 5종 (검색, 브리핑, 비교, 시각화, 용어집) |
| 프롬프트 템플릿 | 9개 (.md 파일) |

### 정성적 성과

- AI 튜터 챗봇을 통해 플랫폼의 핵심 교육 기능을 완성하였다. 사용자가 브리핑 내용에 대해 질문하고, 용어를 학습하며, 시각화 자료를 요청할 수 있는 대화형 학습 환경을 구현하였다.
- 마크다운 기반 프롬프트 관리 시스템을 통해 AI QA 담당자가 프롬프트를 독립적으로 수정하고 테스트할 수 있는 워크플로우를 확립하였다.
- 데이터 파이프라인과 챗봇 간의 공통 AI 모듈을 추출하여 코드 중복을 제거하고, 향후 새로운 LLM 프로바이더를 추가할 때의 확장성을 확보하였다.
- 파이프라인 후처리 자동화(캐시 무효화, MV 리프레시)를 통해 데이터 최신성을 보장하는 운영 안정성을 달성하였다.
- Redis 캐싱 도입으로 API 응답 성능을 개선하여 사용자 체감 속도를 향상시켰다.
