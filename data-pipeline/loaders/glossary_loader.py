"""
ì£¼ì‹ ìš©ì–´ ì‹œë“œ ë°ì´í„° ë¡œë”
JSON íŒŒì¼ì—ì„œ ìš©ì–´ë¥¼ ì½ì–´ PostgreSQLì— ì €ì¥
"""

import json
import asyncio
from pathlib import Path
from datetime import datetime
import sys

# ìƒìœ„ ë””ë ‰í† ë¦¬ ì¶”ê°€ (backend-api ëª¨ë¸ ì‚¬ìš©)
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "backend-api"))

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from dotenv import load_dotenv
import os

# .env ë¡œë“œ
env_path = Path(__file__).parent.parent.parent / ".env"
load_dotenv(env_path)


def get_database_url() -> str:
    """ë™ê¸° ë“œë¼ì´ë²„ìš© DATABASE_URL ë°˜í™˜"""
    url = os.getenv("DATABASE_URL", "")
    # asyncpg -> psycopg2ë¡œ ë³€í™˜
    return url.replace("postgresql+asyncpg", "postgresql+psycopg2")


def load_glossary_seed() -> list[dict]:
    """ì‹œë“œ ë°ì´í„° JSON ë¡œë“œ"""
    seed_path = Path(__file__).parent.parent / "seed_data" / "glossary_seed.json"
    with open(seed_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    return data.get("glossary", [])


def create_glossary_table(engine):
    """glossary í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´)"""
    create_sql = """
    CREATE TABLE IF NOT EXISTS glossary (
        id SERIAL PRIMARY KEY,
        term VARCHAR(100) NOT NULL UNIQUE,
        term_en VARCHAR(100),
        abbreviation VARCHAR(20),
        difficulty VARCHAR(20) NOT NULL DEFAULT 'beginner',
        category VARCHAR(20) NOT NULL DEFAULT 'basic',
        definition_short VARCHAR(200) NOT NULL,
        definition_full TEXT,
        example TEXT,
        formula VARCHAR(200),
        related_terms TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    
    -- ì¸ë±ìŠ¤ ìƒì„±
    CREATE INDEX IF NOT EXISTS idx_glossary_difficulty ON glossary(difficulty);
    CREATE INDEX IF NOT EXISTS idx_glossary_category ON glossary(category);
    CREATE INDEX IF NOT EXISTS idx_glossary_term ON glossary(term);
    """
    with engine.connect() as conn:
        conn.execute(text(create_sql))
        conn.commit()
    print("âœ… glossary í…Œì´ë¸” ìƒì„±/í™•ì¸ ì™„ë£Œ")


def insert_glossary_data(engine, glossary_list: list[dict]):
    """ìš©ì–´ ë°ì´í„° ì‚½ì… (upsert)"""
    insert_sql = """
    INSERT INTO glossary (
        term, term_en, abbreviation, difficulty, category,
        definition_short, definition_full, example, formula, related_terms,
        created_at, updated_at
    ) VALUES (
        :term, :term_en, :abbreviation, :difficulty, :category,
        :definition_short, :definition_full, :example, :formula, :related_terms,
        CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
    )
    ON CONFLICT (term) DO UPDATE SET
        term_en = EXCLUDED.term_en,
        abbreviation = EXCLUDED.abbreviation,
        difficulty = EXCLUDED.difficulty,
        category = EXCLUDED.category,
        definition_short = EXCLUDED.definition_short,
        definition_full = EXCLUDED.definition_full,
        example = EXCLUDED.example,
        formula = EXCLUDED.formula,
        related_terms = EXCLUDED.related_terms,
        updated_at = CURRENT_TIMESTAMP
    """
    
    with engine.connect() as conn:
        for item in glossary_list:
            conn.execute(text(insert_sql), item)
        conn.commit()
    
    print(f"âœ… {len(glossary_list)}ê°œ ìš©ì–´ ì‚½ì…/ì—…ë°ì´íŠ¸ ì™„ë£Œ")


def get_glossary_stats(engine) -> dict:
    """ìš©ì–´ í†µê³„ ì¡°íšŒ"""
    stats_sql = """
    SELECT 
        difficulty,
        COUNT(*) as count
    FROM glossary
    GROUP BY difficulty
    ORDER BY 
        CASE difficulty
            WHEN 'beginner' THEN 1
            WHEN 'elementary' THEN 2
            WHEN 'intermediate' THEN 3
        END
    """
    
    with engine.connect() as conn:
        result = conn.execute(text(stats_sql))
        stats = {row[0]: row[1] for row in result}
    
    return stats


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("=" * 50)
    print("ğŸ“š ì£¼ì‹ ìš©ì–´ ì‹œë“œ ë°ì´í„° ë¡œë”")
    print("=" * 50)
    
    # DB ì—°ê²°
    db_url = get_database_url()
    if not db_url:
        print("âŒ DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ”— DB ì—°ê²°: {db_url.split('@')[1] if '@' in db_url else db_url}")
    
    try:
        engine = create_engine(db_url)
        
        # í…Œì´ë¸” ìƒì„±
        create_glossary_table(engine)
        
        # ì‹œë“œ ë°ì´í„° ë¡œë“œ
        glossary_list = load_glossary_seed()
        print(f"ğŸ“„ ì‹œë“œ ë°ì´í„°: {len(glossary_list)}ê°œ ìš©ì–´")
        
        # ë°ì´í„° ì‚½ì…
        insert_glossary_data(engine, glossary_list)
        
        # í†µê³„ ì¶œë ¥
        stats = get_glossary_stats(engine)
        print("\nğŸ“Š ë‚œì´ë„ë³„ ìš©ì–´ ìˆ˜:")
        difficulty_labels = {
            "beginner": "ì…ë¬¸",
            "elementary": "ì´ˆê¸‰", 
            "intermediate": "ì¤‘ê¸‰"
        }
        for diff, count in stats.items():
            label = difficulty_labels.get(diff, diff)
            print(f"   - {label}: {count}ê°œ")
        
        total = sum(stats.values())
        print(f"   - ì´ê³„: {total}ê°œ")
        
        print("\nâœ… ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        raise


if __name__ == "__main__":
    main()
